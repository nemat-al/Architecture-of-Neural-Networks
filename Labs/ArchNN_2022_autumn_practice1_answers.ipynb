{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2HEtgbfUJJd8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "58c7313889184f6d86bf2d4a38b5f2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bc08c9072b84dafbc40585a539c8ecc",
              "IPY_MODEL_569fc52b47694596a445c4ef4bad4a0f",
              "IPY_MODEL_bd4e8abcddb0424881a57756e7884195"
            ],
            "layout": "IPY_MODEL_3e3dac148f8b4928ab120e89ce74f35d"
          }
        },
        "1bc08c9072b84dafbc40585a539c8ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2134ea54762a4f6b915ca0a89560a925",
            "placeholder": "​",
            "style": "IPY_MODEL_73102e2f2ef04b8a841d0d384e987792",
            "value": "100%"
          }
        },
        "569fc52b47694596a445c4ef4bad4a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3fa45ff8ad24615baf8bbe18ee102a7",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_019b7849cfc0463a8260e23dfc3ffeb9",
            "value": 2000
          }
        },
        "bd4e8abcddb0424881a57756e7884195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee34a2f7cb8f49d1831afcfa14995688",
            "placeholder": "​",
            "style": "IPY_MODEL_71f1795138214ba4bce893d9868e32c6",
            "value": " 2000/2000 [00:24&lt;00:00, 104.43it/s]"
          }
        },
        "3e3dac148f8b4928ab120e89ce74f35d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2134ea54762a4f6b915ca0a89560a925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73102e2f2ef04b8a841d0d384e987792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3fa45ff8ad24615baf8bbe18ee102a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "019b7849cfc0463a8260e23dfc3ffeb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee34a2f7cb8f49d1831afcfa14995688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71f1795138214ba4bce893d9868e32c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1. PyTorch introductory assignments\n",
        "\n",
        "PyTorch exercises for those who want to remember the basics of framefork."
      ],
      "metadata": {
        "id": "6W-qyOTPct9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main framework\n",
        "import torch\n",
        "# additional functions on tensors or networks\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# work with arrays in pure python\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "KobPC6g8cxPN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Tensors creation\n",
        "Tensors is a data structure optimized for automatic differentiation. In most cases, working with them is similar to working with arrays in numpy.\n",
        "\n",
        "We use `torch.tensor()` to create tensor object from pure Python and Numpy objects."
      ],
      "metadata": {
        "id": "-3P3iL68dm21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. From list"
      ],
      "metadata": {
        "id": "H_2lnqdFHG-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_lst = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_from_lst = torch.tensor(data_lst)"
      ],
      "metadata": {
        "id": "Q44dHwvGdgtV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(tensor_from_lst.dtype == torch.int64)\n",
        "assert(tensor_from_lst.shape == torch.Size([3, 3]))"
      ],
      "metadata": {
        "id": "mjwKxHWyIAGT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. From Numpy array\n",
        "\n"
      ],
      "metadata": {
        "id": "2HEtgbfUJJd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_ndarray = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_from_numpy = torch.tensor(data_ndarray)"
      ],
      "metadata": {
        "id": "B3JJ7L7jJiaL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(tensor_from_numpy.dtype == torch.int64)\n",
        "assert(tensor_from_numpy.shape == torch.Size([3, 3]))"
      ],
      "metadata": {
        "id": "HDoWDqiPKXAT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also try to use `torch.from_numpy()` on the following array to understand the differences between this function and `torch.tensor()`"
      ],
      "metadata": {
        "id": "0y6JfgzAKYxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_ndarray2 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_using_from_numpy = torch.from_numpy(data_ndarray2)"
      ],
      "metadata": {
        "id": "dIewLwK3Kxbj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_from_numpy *= 0\n",
        "tensor_using_from_numpy *= 0"
      ],
      "metadata": {
        "id": "KqJs5outLhCb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(all(data_ndarray[0] == [1, 2, 3]))\n",
        "assert(all(data_ndarray2[0] == [0, 0, 0]))"
      ],
      "metadata": {
        "id": "OJQnlGPGMp9D"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, `torch.from_numpy()` create tensor that share the memory with ndarray, therefore, any changes also affect the original array."
      ],
      "metadata": {
        "id": "3NlO_PBEU-73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Using default values"
      ],
      "metadata": {
        "id": "IXTSVYbfNSZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_shape = (2, 3, 4)\n",
        "\n",
        "# Creating a tensor of a given shape filled with zeros\n",
        "tensor_zeros = torch.zeros(data_shape)\n",
        "print('Zero:\\n{}'.format(tensor_zeros))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hz-u_gYLr27",
        "outputId": "39a8615d-54a5-4b9e-83de-a27a2073ea55"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero:\n",
            "tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor of a given shape filled with ones\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_ones = torch.ones(data_shape)\n",
        "\n",
        "# Create tensor of a given shape filled with random numbers\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_rand = torch.rand(data_shape)"
      ],
      "metadata": {
        "id": "JRj4ZOSCQz-E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(all(tensor_ones[0][0] == torch.tensor([1., 1., 1., 1.])))\n",
        "assert(tensor_ones.shape == torch.Size(data_shape))\n",
        "assert(tensor_rand.shape == torch.Size(data_shape))"
      ],
      "metadata": {
        "id": "VORnV5CrSB1C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also create tensor from sequence using `torch.arange()` and then use `tensor.reshape()` function to convert data into the desired shape."
      ],
      "metadata": {
        "id": "6PfdPfD2RNkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "range_len = 24\n",
        "# Create tensor filled with sequential values from 0 to range_len\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_seq = torch.arange(24)\n",
        "\n",
        "# Convert the shape of the created tensor to fit data_shape\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_seq_reshaped = tensor_seq.reshape(data_shape)"
      ],
      "metadata": {
        "id": "4cBezVXLRNEs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(tensor_seq[0] == torch.tensor(0))\n",
        "assert(tensor_seq[-1] == torch.tensor(range_len - 1))\n",
        "assert(tensor_seq.shape ==torch.Size([range_len]))"
      ],
      "metadata": {
        "id": "pfgHhd2jVItb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(tensor_seq_reshaped[0][0][0] == torch.tensor(0))\n",
        "assert(tensor_seq_reshaped[-1][-1][-1] == torch.tensor(range_len - 1))\n",
        "assert(tensor_seq_reshaped.shape == torch.Size(data_shape))"
      ],
      "metadata": {
        "id": "6lD4IBMFRsEL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to make a tensor with a shape of another tensor, but with default values, you can use `torch.values_like()` functions"
      ],
      "metadata": {
        "id": "w8iarPvOXXXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand((1, 2, 2))\n",
        "\n",
        "# For example, you want to create a mask for the image or something filled with zeros\n",
        "tensor_mask = torch.zeros_like(tensor)\n",
        "print('Image:\\n{}'.format(tensor))\n",
        "print('Image_mask:\\n{}'.format(tensor_mask))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiYRWNOMQJFk",
        "outputId": "18ef2bb3-19a7-47d8-f3fa-1fdbd0611cff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image:\n",
            "tensor([[[0.2957, 0.6729],\n",
            "         [0.9868, 0.9558]]])\n",
            "Image_mask:\n",
            "tensor([[[0., 0.],\n",
            "         [0., 0.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using similar functions, create a tensor mask filled with ones and a mask filled with the random values"
      ],
      "metadata": {
        "id": "-CQ-VUHgX7Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mask, filled with ones (with a shape of tensor)\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_mask_ones = torch.ones_like(tensor)\n",
        "\n",
        "# Mask, filled with random values (with a shape of tensor)\n",
        "''' YOUR CODE HERE '''\n",
        "tensor_mask_rand = torch.rand_like(tensor)"
      ],
      "metadata": {
        "id": "62UbgUOzINGK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(tensor_mask_ones[0][0][0] == torch.tensor(1.))\n",
        "assert(tensor_mask_ones.shape == tensor.shape)\n",
        "assert(tensor_mask_rand.shape == tensor.shape)"
      ],
      "metadata": {
        "id": "gAu-GFSiYaQp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Devices\n",
        "\n",
        "Tensors can be stored in general memory, GPU memory, TPU memory."
      ],
      "metadata": {
        "id": "8_G6jrftZOsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand((2, 5, 5))\n",
        "print(tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpmBNwwPYu1R",
        "outputId": "a7f260f9-fe0c-4dc1-c4e1-aa09bc4f2b5d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the further assignments you should use Google Colab with GPU (Runtime -> Change Runtime Type -> Hardware Accelerating) and store tensors in GPU memory."
      ],
      "metadata": {
        "id": "YUD2xWiTbc48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "wDOy0VX6bmDL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move tensor to the GPU memory\n",
        "''' YOUR CODE HERE '''\n",
        "tensor = tensor.to(device)"
      ],
      "metadata": {
        "id": "cteUw9WwaDT5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(tensor.device.type == 'cuda')"
      ],
      "metadata": {
        "id": "rNMyYsp9abgS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Autograd\n",
        "\n",
        "Auto differentiation is a core of ML frameworks. PyTorch can figure out the computation of gradients for a set of operations. Almost all pytorch operations are differentiable.\n",
        "\n",
        "`required_grad=True` make PyTorch to store gradients for this particular tensor. Usually, for input values this parameters is set to False - we don't want to change our real data."
      ],
      "metadata": {
        "id": "FX-vmw5tb6jU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor = torch.rand((2, 4, 4), requires_grad=True)\n",
        "tensor = torch.ones((2, 4, 4))\n",
        "tensor.requires_grad = True"
      ],
      "metadata": {
        "id": "I5gMYz1jas4J"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define function y\n",
        "y = 5 * tensor ** 3 - 3\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3mOapZqeKbJ",
        "outputId": "9bc2aa8f-9d49-4f8a-f831-526589e485c7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2., 2., 2., 2.],\n",
            "         [2., 2., 2., 2.],\n",
            "         [2., 2., 2., 2.],\n",
            "         [2., 2., 2., 2.]],\n",
            "\n",
            "        [[2., 2., 2., 2.],\n",
            "         [2., 2., 2., 2.],\n",
            "         [2., 2., 2., 2.],\n",
            "         [2., 2., 2., 2.]]], grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsQqec9DeMuB",
        "outputId": "8880f052-1e82-472f-d1b0-431eb57abafd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no gradient for our tensor, because we have to call `.backward() ` method of variable $y$. This method will calculate gradien of $y$ over variable tensor\n",
        "\n",
        "NOTE: gradient can be calculated only for a scalar. The output of $y$ is a tensor, we can calculate mean(), sum(), etc"
      ],
      "metadata": {
        "id": "r5Tnnn-5ehDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the backward method and calculate gradient for the sum of the y variable\n",
        "''' YOUR CODE HERE '''\n",
        "y.sum().backward()"
      ],
      "metadata": {
        "id": "MTcL7kXSePLh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(tensor.grad.shape == torch.Size([2, 4, 4]))\n",
        "assert(tensor.grad[0][0][0] == torch.tensor(15))"
      ],
      "metadata": {
        "id": "j4BbcuK-eRTJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** \n",
        "* you can not run `.backward()` again without calculating y value again;\n",
        "* if you run y function one more time the gradient values for tensor variable will be summed."
      ],
      "metadata": {
        "id": "-N-xsoeofiFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the backward method again and calculate gradient for the sum of the y variable\n",
        "''' YOUR CODE HERE '''\n",
        "y = 5 * tensor ** 3 - 3\n",
        "y.sum().backward()"
      ],
      "metadata": {
        "id": "zWjIrpwof4Pa"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(tensor.grad.shape == torch.Size([2, 4, 4]))\n",
        "assert(tensor.grad[0][0][0] == torch.tensor(30))"
      ],
      "metadata": {
        "id": "yhve93SVfLsB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Neural network in PyTorch\n",
        "\n",
        "NN in PyTorch defines as a set of different layers. Each layer is a specific function:\n",
        "\n",
        "\n",
        "*   Linear layer, convolutional layer, etc\n",
        "*   Activation function\n",
        "*   Tensors operations\n",
        "\n",
        "The first type has parameters called weights and biases.The process of NN training is to change weights of NN layers so the prediction of network will match the real object.\n"
      ],
      "metadata": {
        "id": "APlEpRyTgFST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear layer\n",
        "\n",
        "[torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) takes a matrix $(N, *, H_{in})$ and produce a matrix $(N, *, H_{out})$, where\n",
        "\n",
        "$*$ means any number of additional dimensions, $H_{in}$ - input features, $H_{out}$ - output features\n",
        "\n",
        "Linear layer is a $W \\cdot x + b$ operation, where $W$ - weights of the layer and $b$ - bias. Bias can be ommited with `bias=False`"
      ],
      "metadata": {
        "id": "YlvtVVDmgcv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.ones((3, 5))\n",
        "print('input shape: ', input_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m8BLBtOfbT6",
        "outputId": "69caa4e6-ae0d-46e3-f496-c795db3461e9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape:  torch.Size([3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We fed sample of data with batch_size=3 and features of each sample=5. \n",
        "\n",
        "All samples in a batch processed separately. This is true for all layers and functions of PyTorch."
      ],
      "metadata": {
        "id": "QQfOM30-hX37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a linear layer for given data with the number of out_features=100 and ommited bias (don't forget about GPU)\n",
        "''' YOUR CODE HERE '''\n",
        "layer = torch.nn.Linear(in_features=5, out_features=100, bias=False, device=device)"
      ],
      "metadata": {
        "id": "CLpsiSGshFvb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at layers parameters. \n",
        "\n",
        "`layer.paramaters()` outputs a generator of all weights and biases of this object."
      ],
      "metadata": {
        "id": "qJepe-jlh5Pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(layer.parameters()))\n",
        "# iterate over layer parameters and print shapes\n",
        "for i in layer.parameters():\n",
        "    print(i.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS3o9IikhJoQ",
        "outputId": "d32f1537-ec2c-4ddf-907d-0594570d80c3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'generator'>\n",
            "torch.Size([100, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should receive the following output:\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "D6J6Gi3qiDIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single layer contains only one weight matrix of shape (H_out, H_in). You can access the weights of a layer directly, using `layer.weight` method"
      ],
      "metadata": {
        "id": "u7KbPhOUiSDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(layer.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oPpsDNRiB8T",
        "outputId": "34decceb-c47b-4962-eaef-641a9c476507"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can move layer from CPU to GPU in the same way as tensor."
      ],
      "metadata": {
        "id": "4xP6UY8GioBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer.to('cpu') # or layer.cpu() for simplicity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlFkkXb4iZgB",
        "outputId": "f135d7bb-0423-4301-9cde-6e490113859e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=5, out_features=100, bias=False)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer.to('cuda:0')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_JICUxwisUh",
        "outputId": "33b0b53f-a157-42c5-bf15-cae62268ff34"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=5, out_features=100, bias=False)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network\n",
        "\n",
        "You can write a NN as a set of layers and then apply them sequentially"
      ],
      "metadata": {
        "id": "Q7EFV0g-i48a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.rand((3, 5))\n",
        "\n",
        "# Create three sequential linear layers for the given input tensor. First two with the output 100 and the last one with the output 3.\n",
        "# Apply them sequentially and store in the output\n",
        "''' YOUR CODE HERE '''\n",
        "\n",
        "layer1 = torch.nn.Linear(5, 100)\n",
        "layer2 = torch.nn.Linear(100, 100)\n",
        "layer3 = torch.nn.Linear(100, 3)\n",
        "\n",
        "output = layer3(layer2(layer1(input_tensor)))\n",
        "'''\n",
        "Another way of writing it\n",
        "layer_1 = torch.nn.Linear (in_features = 5 , out_features=100, bias= False)\n",
        "layer_2 = torch.nn.Linear (in_features = 100 , out_features=100, bias= False)\n",
        "layer_3 = torch.nn.Linear (in_features = 100 , out_features=3, bias= False)\n",
        "output = layer_3(layer_2(layer_1(input_tensor)))\n",
        "'''\n"
      ],
      "metadata": {
        "id": "Ab1xdz34iu5x"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(output.shape == torch.Size([3, 3]))"
      ],
      "metadata": {
        "id": "_zpoyRpZjEqp"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activation and loss functions"
      ],
      "metadata": {
        "id": "6HKHRg8UkLfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use different activation functions from `torch.nn` and combine them sequentially with the NN layers"
      ],
      "metadata": {
        "id": "GwzcN4uGkXAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of the activation function\n",
        "torch.nn.ReLU6()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9J8DHXGjO1J",
        "outputId": "934c60e0-3c29-4531-dbfd-47f040b3690a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ReLU6()"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use different loss functions from `torch.nn`"
      ],
      "metadata": {
        "id": "AmXDvB9Hkq7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of the loss function\n",
        "loss_function = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "CMv12O20krIq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Feedforward Neural Network construction assignment "
      ],
      "metadata": {
        "id": "04nXIR3jkA1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all the necessary libraries"
      ],
      "metadata": {
        "id": "J3E6eNqIl5PM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "SEED = 0\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "ElBSbXRBkKUr"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the `plot_decision_regions` we should additionally install the `mlxtend` package"
      ],
      "metadata": {
        "id": "y8JoJwwamJPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlxtend"
      ],
      "metadata": {
        "id": "VIAJAIG2l4Vq",
        "outputId": "c19f5415-b0dc-4764-b7ad-f95f6c47bf9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.4.0)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.3.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.7.3)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.5.1->mlxtend) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2022.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading dataset\n",
        "\n",
        "Let's upload the wine dataset from sklearn"
      ],
      "metadata": {
        "id": "kN4gvrl5md66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine = sklearn.datasets.load_wine()\n",
        "wine.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ff10ac-aadb-41d2-c1dd-a8f7792017ef",
        "id": "OqpEifG18Cf0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "wine_df = pd.DataFrame(data=wine.data)"
      ],
      "metadata": {
        "id": "-8UjT_3HFX23"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "oJkAbTUgA9k6"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine_data_normalized = preprocessing.normalize(wine_df)\n",
        "wine_df = pd.DataFrame(data=wine_data_normalized)"
      ],
      "metadata": {
        "id": "ze-XARjtBIMS"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create class for the dataset. Inherit a class from Dataset"
      ],
      "metadata": {
        "id": "ZzmI_lNKs7M5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill the WineDataset class fields\n",
        "class WineDataset():\n",
        "    def __init__(self, X, y):\n",
        "        ''' YOUR CODE HERE '''\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    \n",
        "    def __len__(self):\n",
        "        ''' YOUR CODE HERE '''\n",
        "        return self.X.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        ''' YOUR CODE HERE '''\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "1oTZKhTymtUE"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create train and test splits using `train_test_split` function with the following parameters:\n",
        "\n",
        "* size of test - 30%\n",
        "* using shuffle\n",
        "* using SEED constant for the random state\n",
        "\n",
        "Remember that use should use WineDataset class."
      ],
      "metadata": {
        "id": "wzd8eZoUtrL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' ANOTHER WAY\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    wine['data'],wine['target'],\n",
        "    test_size=0.3,shuffle=True,\n",
        "     random_state=SEED)\n",
        "train_dataset = WineDataset(torch.tensor(X_train).to(device),torch.tensor(y_train).to(device))\n",
        "test_dataset = WineDataset(torch.tensor(X_test).to(device),torch.tensor(y_test).to(device))'''\n",
        "\n",
        "''' YOUR CODE HERE '''\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    wine_data_normalized[:].astype(np.float32),\n",
        "    wine.target.astype(int),\n",
        "    test_size=0.3,\n",
        "    shuffle=True,\n",
        "    random_state=SEED)\n",
        "\n",
        "train_dataset = WineDataset(X_train, y_train)\n",
        "test_dataset = WineDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "-rizvl_0tiBq"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(len(train_dataset) == 124)\n",
        "assert(len(test_dataset) == 54)"
      ],
      "metadata": {
        "id": "t3hIxoW7uY-D"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Feedforward network\n",
        "\n",
        "Create the FNN with the following attributes:\n",
        "* 3 linear layers\n",
        "* activation functions on your choice (the most suitable for this kind of task)"
      ],
      "metadata": {
        "id": "4-qto2JZuw4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' YOUR CODE HERE '''\n",
        "INPUT_SIZE = train_dataset.X.shape[1]\n",
        "OUTPUT_SIZE = len(np.unique(train_dataset.y))\n",
        "\n",
        "class WineNet(nn.Module):\n",
        "    def __init__(self, n_hidden_neurons):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(INPUT_SIZE, n_hidden_neurons)\n",
        "        self.activ1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(n_hidden_neurons, n_hidden_neurons)\n",
        "        self.activ2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(n_hidden_neurons, OUTPUT_SIZE)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.activ1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.activ2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    # для использования в функции plot_decision_regions\n",
        "    def predict(self, x):\n",
        "        ''' PLEASE DO NOT CHANGE THE CODE OF THIS FUNCTION '''\n",
        "        x = torch.tensor(x, dtype=torch.float32).to(device)\n",
        "        with torch.no_grad():\n",
        "            x = self.forward(x)\n",
        "        x = x.cpu().argmax(dim=-1)\n",
        "        x = x.data.numpy()\n",
        "        return x"
      ],
      "metadata": {
        "id": "J80UqErYuZAL"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = WineNet(10) # you can change parameters here\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "TCFnDMR3vl_a"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BIMA0R-9i4u",
        "outputId": "cccbe938-1c02-4cfc-aff7-aa2d91eac259"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WineNet(\n",
              "  (fc1): Linear(in_features=13, out_features=10, bias=True)\n",
              "  (activ1): ReLU()\n",
              "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
              "  (activ2): ReLU()\n",
              "  (fc3): Linear(in_features=10, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training FNN"
      ],
      "metadata": {
        "id": "JB3p3LdpwAdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the loss function and initialize and tune the optimizer and scheduler  \n",
        "''' YOUR CODE HERE '''\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1.0e-2)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=500, eta_min=1.0e-4)"
      ],
      "metadata": {
        "id": "SU5dJkJZv6m5"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the code for the model training process.\n",
        "\n",
        "NOTE: You can memorize the best metric value and weight in the colab with the commands \n",
        "\n",
        "`torch.save(model.state_dict(), STATE_DICT_PATH)`, and `load model.load_state_dict(torch.load(STATE_DICT_PATH))`"
      ],
      "metadata": {
        "id": "aBn87Xy0xNSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' YOUR CODE HERE '''\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS_NUM = 2000\n",
        "\n",
        "''' PLEASE DO NOT CHANGE THE CODE OF THESE LINES '''\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
        "\n",
        "# choose any metric from sklearn for multiclass classification\n",
        "''' YOUR CODE HERE '''\n",
        "metric_fn = metrics.balanced_accuracy_score\n",
        "\n",
        "best_metric = None\n",
        "STATE_DICT_PATH = 'best_model_state_dict.pt'\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS_NUM)):\n",
        "    model.train()\n",
        "    for x, y in train_loader:\n",
        "        ''' YOUR CODE HERE '''\n",
        "        # Several lines\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        x = x.to(device)\n",
        "        preds = model.forward(x)\n",
        "        preds = preds.cpu()\n",
        "        \n",
        "        loss_value = loss(preds, y)\n",
        "        loss_value.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "        \n",
        "    if epoch % 100 == 0:\n",
        "        model.eval()\n",
        "        test_preds = []\n",
        "        true = []\n",
        "        # with the no_grad() option, the gradients of the weights do not count\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_loader:\n",
        "                ''' YOUR CODE HERE '''\n",
        "                x = x.to(device)\n",
        "                preds = model.forward(x)\n",
        "                preds = preds.cpu()\n",
        "\n",
        "                test_preds.append(preds)\n",
        "                true.append(y)\n",
        "\n",
        "        \n",
        "        test_preds = torch.cat(test_preds).squeeze()\n",
        "        true = torch.cat(true).squeeze()\n",
        "        test_loss = loss(test_preds, true).item()\n",
        "        test_metric = metric_fn(true, test_preds.argmax(dim=-1))\n",
        "        \n",
        "        \n",
        "        ''' YOUR CODE HERE '''\n",
        "        # Only if you want to save the best state\n",
        "        if best_metric is None or best_metric < test_metric:\n",
        "            best_metric = test_metric\n",
        "            torch.save(model.state_dict(), STATE_DICT_PATH)\n",
        "\n",
        "        print(f'Test loss: {test_loss:0.4f}\\t\\tTest metric: {test_metric:0.4f}')\n",
        "\n",
        "print('Best metric:', best_metric)\n",
        "model.load_state_dict(torch.load(STATE_DICT_PATH))"
      ],
      "metadata": {
        "id": "JB7wbCFuwSIh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431,
          "referenced_widgets": [
            "58c7313889184f6d86bf2d4a38b5f2ea",
            "1bc08c9072b84dafbc40585a539c8ecc",
            "569fc52b47694596a445c4ef4bad4a0f",
            "bd4e8abcddb0424881a57756e7884195",
            "3e3dac148f8b4928ab120e89ce74f35d",
            "2134ea54762a4f6b915ca0a89560a925",
            "73102e2f2ef04b8a841d0d384e987792",
            "f3fa45ff8ad24615baf8bbe18ee102a7",
            "019b7849cfc0463a8260e23dfc3ffeb9",
            "ee34a2f7cb8f49d1831afcfa14995688",
            "71f1795138214ba4bce893d9868e32c6"
          ]
        },
        "outputId": "152a2447-5adf-4f2e-ffcc-93674a536282"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58c7313889184f6d86bf2d4a38b5f2ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.0815\t\tTest metric: 0.3333\n",
            "Test loss: 0.5723\t\tTest metric: 0.6479\n",
            "Test loss: 0.2719\t\tTest metric: 0.9673\n",
            "Test loss: 0.1792\t\tTest metric: 0.9522\n",
            "Test loss: 0.1646\t\tTest metric: 0.9522\n",
            "Test loss: 0.1620\t\tTest metric: 0.9522\n",
            "Test loss: 0.1507\t\tTest metric: 0.9522\n",
            "Test loss: 0.1537\t\tTest metric: 0.9370\n",
            "Test loss: 0.1438\t\tTest metric: 0.9522\n",
            "Test loss: 0.1512\t\tTest metric: 0.9522\n",
            "Test loss: 0.1574\t\tTest metric: 0.9370\n",
            "Test loss: 0.1685\t\tTest metric: 0.9522\n",
            "Test loss: 0.1527\t\tTest metric: 0.9522\n",
            "Test loss: 0.1558\t\tTest metric: 0.9522\n",
            "Test loss: 0.1590\t\tTest metric: 0.9522\n",
            "Test loss: 0.1578\t\tTest metric: 0.9522\n",
            "Test loss: 0.1784\t\tTest metric: 0.9522\n",
            "Test loss: 0.1925\t\tTest metric: 0.9522\n",
            "Test loss: 0.1747\t\tTest metric: 0.9522\n",
            "Test loss: 0.1870\t\tTest metric: 0.9522\n",
            "Best metric: 0.967304625199362\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model evaluation\n",
        "\n",
        "You should create a model with the F1-score greater than 0.87"
      ],
      "metadata": {
        "id": "oaF116Zdxsax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_preds = []\n",
        "true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x = x.to(device)\n",
        "        preds = model.forward(x).cpu()\n",
        "        test_preds.append(preds)\n",
        "        true.append(y)\n",
        "test_preds = torch.cat(test_preds).squeeze()\n",
        "true = torch.cat(true).squeeze()\n",
        "test_metric = metrics.f1_score(true, test_preds.argmax(dim=-1), average='macro')\n",
        "\n",
        "print('F1-score on test:', test_metric)\n",
        "if not test_metric >= 0.87:\n",
        "    raise AssertionError(\"You need to get f1_score greater or equal to 0.87\")"
      ],
      "metadata": {
        "id": "N4Qal9n4x5ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c9c5401-c144-45c0-a429-2722238f3c51"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score on test: 0.967304625199362\n"
          ]
        }
      ]
    }
  ]
}